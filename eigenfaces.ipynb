{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzipping, splitting and preprocessing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file fer2013.tar.gz must be in the same directory as the notebook\n",
    "!tar -xf fer2013.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\Maksim Komatovskiy\\Desktop\\cv_proj \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "os.chdir(os.getcwd() + '/fer2013')\n",
    "full_data = pd.read_csv('fer2013.csv')\n",
    "os.chdir('../')\n",
    "print('Current directory: {} \\n'.format(os.getcwd()))\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here different helper functions are created\n",
    "\n",
    "def str2array(string):\n",
    "    img_array = np.array(string.split(' ')).astype(np.int64)\n",
    "    return img_array\n",
    "\n",
    "def create_subset_labeled_with(label,full_data):\n",
    "    subdata = full_data[full_data['emotion'] == label]\n",
    "    return subdata\n",
    "\n",
    "def construct_a_batch(list_of_datasets,size_by_ten):\n",
    "    batch = pd.DataFrame()\n",
    "    \n",
    "    for sub in list_of_datasets:\n",
    "        idx = np.random.randint(0,len(sub),size_by_ten)\n",
    "        subb = sub.iloc[idx]\n",
    "        batch = pd.concat([batch,subb])\n",
    "    return batch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_F_matrix_from_subdataset(subdataset):\n",
    "    F0 = subdataset['pixels'].iloc[0].reshape(-1,1)\n",
    "\n",
    "    for i in tqdm(range(1, len(subdataset))):\n",
    "        F0 = np.append(F0,subdataset['pixels'].iloc[i].reshape(-1,1),axis = 1)\n",
    "        \n",
    "    return F0\n",
    "\n",
    "def mean_column(A):\n",
    "    return A.mean(axis = 1)\n",
    "\n",
    "def subtract_column_mean(A):\n",
    "    column_mean = mean_column(A)\n",
    "    return A - column_mean.reshape(-1,1)\n",
    "\n",
    "def approximate_with_rank(A,r,return_decomposition = False):\n",
    "\n",
    "    u,s,vh = np.linalg.svd(A,full_matrices = False) # decomposition\n",
    "    #print(u.shape, s.shape,vh.shape)\n",
    "    s = s[:r] #truncation\n",
    "    u = u[:,:r]\n",
    "    vh = vh[:r,:]\n",
    "    #print(u.shape, s.shape,vh.shape)\n",
    "    \n",
    "    if return_decomposition:\n",
    "        return u,s,vh\n",
    "    else:\n",
    "        A_ = np.dot(u,np.dot(np.diag(s),vh))\n",
    "        return A_\n",
    "\n",
    "def plot_eigf(U0,y):\n",
    "    for i in range(y):\n",
    "        f = U0[:,i]\n",
    "        f = f.reshape(48,48)\n",
    "        plt.figure(figsize = (8,8))\n",
    "        plt.imshow(f,cmap = 'gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the data in the dataframes into the usable format\n",
    "\n",
    "full_data['pixels'] = full_data['pixels'].apply(lambda x: str2array(x))\n",
    "\n",
    "full_data['emotion'] = full_data['emotion'].apply(lambda x: np.int64(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the column usage, in our case it is quite useless\n",
    "\n",
    "del full_data['Usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random train-test split\n",
    "\n",
    "random.seed = 42\n",
    "\n",
    "test_percentage = 0.1\n",
    "\n",
    "test_indices = np.random.choice(range(0,len(full_data)),\n",
    "                                      size = int(test_percentage*len(full_data)),\n",
    "                                      replace = False)\n",
    "\n",
    "test_set = full_data.iloc[test_indices]\n",
    "full_data.drop(test_indices,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3588, 2)\n",
      "(32299, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_set.shape)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking a glipse over how do the images look like\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img0 = full_data['pixels'].iloc[100].reshape(48,48)\n",
    "plt.imshow(img0, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The ovarall idea of the pipeline\n",
    "\n",
    "# We need to form some dataset with balanced classes, e.g. 100 random images from each category\n",
    "# Then we build and approximation matrix F_norm, which can be induced by subtracting the mean and SVD truncation of the residual\n",
    "# We project the test images on our singular vector space and therefore we find the closest from the prospect of the cosine similarity image to the test one\n",
    "# We predict the label of the test image to be the same, as the label og the closest train one\n",
    "\n",
    "# We stabilize the result by feeding e.g. 11 different subdatasets (one may call them batches) to our model and decide the total prediction by common majority vote\n",
    "\n",
    "\n",
    "### NB f1_score would be used as the measure of quality in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to work on the non-preprocessed, raw dataset for the moment\n",
    "\n",
    "# we create subdatasets to work with eigenfaces\n",
    "\n",
    "subdata_0 = create_subset_labeled_with(0,full_data)\n",
    "subdata_1 = create_subset_labeled_with(1,full_data)\n",
    "subdata_2 = create_subset_labeled_with(2,full_data)\n",
    "subdata_3 = create_subset_labeled_with(3,full_data)\n",
    "subdata_4 = create_subset_labeled_with(4,full_data)\n",
    "subdata_5 = create_subset_labeled_with(5,full_data)\n",
    "subdata_6 = create_subset_labeled_with(6,full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [subdata_0,\n",
    "                    subdata_1,\n",
    "                    subdata_2,\n",
    "                    subdata_3,\n",
    "                    subdata_4,\n",
    "                    subdata_5,\n",
    "                    subdata_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3587/3587 [01:24<00:00, 42.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# preparing the test data for quality check in the end\n",
    "\n",
    "TEST_BATCH_SIZE = len(test_set)\n",
    "testing_batch = construct_a_batch([test_set],TEST_BATCH_SIZE)\n",
    "F_test = create_F_matrix_from_subdataset(testing_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#HERE STARTS THE RUNNING OF A SINGLE MODEL\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:31<00:00, 65.74it/s]\n",
      "  0%|                                                                                         | 0/2099 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 3588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:29<00:00, 70.99it/s]\n",
      "  0%|                                                                                         | 0/2099 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 3588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2099/2099 [00:28<00:00, 73.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 3588)\n"
     ]
    }
   ],
   "source": [
    "for iters in range(3):\n",
    "\n",
    "    # we construct a class - balanced subdataset\n",
    "\n",
    "    TRAIN_BATCH_SIZE = 300\n",
    "    batch = construct_a_batch(list_of_datasets,TRAIN_BATCH_SIZE)\n",
    "    # sizes must be (7*second_arg,2)\n",
    "\n",
    "    # we construct a matrix by columns (vectorized images of the test dataset)\n",
    "    F0 = create_F_matrix_from_subdataset(batch)\n",
    "\n",
    "    # we subtract the mean column to normalize it\n",
    "\n",
    "    F0_norm = subtract_column_mean(F0)\n",
    "\n",
    "    # we select the approximation strength (rank of truncation), which, obviously, should be less then min(F0.shape[0],F0.shape[1])\n",
    "\n",
    "    R = 20\n",
    "\n",
    "\n",
    "    # we build an R-rank approximation of the centralized F-matrix\n",
    "\n",
    "    F0_norm_approx = approximate_with_rank(F0_norm, r = R)\n",
    "\n",
    "    # we glimpse at the uniformness of approximation mistakes\n",
    "\n",
    "    #plt.spy(F0_norm - F0_norm_approx,10); \n",
    "\n",
    "    # we decompose it again, but now keeping the factors\n",
    "\n",
    "    U0,S0,Vh0 = approximate_with_rank(F0_norm, \n",
    "                                      r = R,\n",
    "                                      return_decomposition=True)\n",
    "\n",
    "    # we have a glimpse at the first columns of the U matrix, which form a basis in the space of faces (first several)\n",
    "    # we wont need it in the last pipeline\n",
    "    #plot_eigf(U0,3)\n",
    "\n",
    "    # to make a projection of the correspondingly dimensioned vector on the subspace of eigenvectors, we need,\n",
    "    # taking into account the properties of U matrix (unitary), to Compute U^t@vec = coefficients in the basis\n",
    "\n",
    "    # jyst a debugging cell to check whether the model works on the only image\n",
    "\n",
    "    test_img_vec = F_test\n",
    "\n",
    "\n",
    "\n",
    "    print(F_test.shape)\n",
    "\n",
    "    # now we need to project our test images on the subspace induced by singular vectors\n",
    "\n",
    "    # we construct a projection matrix (U is unitary)\n",
    "\n",
    "    # the shape would be R by len(vec(img)) = 2304\n",
    "\n",
    "    projection_matrix = U0.T\n",
    "\n",
    "\n",
    "\n",
    "    # performing the projection\n",
    "\n",
    "    f2 = projection_matrix@test_img_vec\n",
    "\n",
    "    # in general in is R by the TEST_BATCH_SIZE\n",
    "\n",
    "\n",
    "\n",
    "    # the correspondency matrix, with which to compare (we search for the image with quite the same coefficients in linear combination)\n",
    "\n",
    "    W = np.diag(S0)@Vh0\n",
    "\n",
    "\n",
    "    dist = (cosine_similarity(f2.T, W.T).argmax(axis=1) + 1)\n",
    "\n",
    "\n",
    "\n",
    "    prediction = batch['emotion'].iloc[dist]\n",
    "    prediction = np.array(prediction)\n",
    "    #print(prediction[:5])\n",
    "    #print(prediction.shape)\n",
    "\n",
    "    y_true = np.array(testing_batch['emotion'])\n",
    "\n",
    "    f1_score(y_true,\n",
    "             prediction,\n",
    "             average='micro')\n",
    "    \n",
    "    PREDICTIONS.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.concatenate(PREDICTIONS[-3:])\n",
    "p = p.reshape(-1,3588)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3588)"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 5, ..., 2, 4, 2],\n",
       "       [0, 1, 5, ..., 4, 5, 5],\n",
       "       [3, 5, 6, ..., 2, 6, 6]], dtype=int64)"
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = np.int64(np.median(p,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16025641025641027"
      ]
     },
     "execution_count": 1019,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_pred,y_true,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 3, ..., 3, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 1020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
