{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzipping, splitting and preprocessing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from skimage.feature import match_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\Maksim Komatovskiy\\Desktop\\cv_proj \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "os.chdir(os.getcwd() + '/fer2013')\n",
    "full_data = pd.read_csv('fer2013.csv')\n",
    "os.chdir('../')\n",
    "print('Current directory: {} \\n'.format(os.getcwd()))\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here different helper functions are created\n",
    "\n",
    "def str2array(string):\n",
    "    img_array = np.array(string.split(' ')).astype(np.int64)\n",
    "    return img_array\n",
    "\n",
    "def create_subset_labeled_with(label,full_data):\n",
    "    subdata = full_data[full_data['emotion'] == label]\n",
    "    return subdata\n",
    "\n",
    "def construct_a_batch(list_of_datasets,size_by_ten):\n",
    "    batch = pd.DataFrame()\n",
    "    \n",
    "    for sub in list_of_datasets:\n",
    "        idx = np.random.randint(0,len(sub),size_by_ten)\n",
    "        subb = sub.iloc[idx]\n",
    "        batch = pd.concat([batch,subb])\n",
    "    return batch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_F_matrix_from_subdataset(subdataset):\n",
    "    F0 = subdataset['pixels'].iloc[0].reshape(-1,1)\n",
    "\n",
    "    for i in tqdm(range(1, len(subdataset))):\n",
    "        F0 = np.append(F0,subdataset['pixels'].iloc[i].reshape(-1,1),axis = 1)\n",
    "        \n",
    "    return F0\n",
    "\n",
    "def mean_column(A):\n",
    "    return A.mean(axis = 1)\n",
    "\n",
    "def subtract_column_mean(A):\n",
    "    column_mean = mean_column(A)\n",
    "    return A - column_mean.reshape(-1,1)\n",
    "\n",
    "def approximate_with_rank(A,r,return_decomposition = False):\n",
    "\n",
    "    u,s,vh = np.linalg.svd(A,full_matrices = False) # decomposition\n",
    "    #print(u.shape, s.shape,vh.shape)\n",
    "    s = s[:r] #truncation\n",
    "    u = u[:,:r]\n",
    "    vh = vh[:r,:]\n",
    "    #print(u.shape, s.shape,vh.shape)\n",
    "    \n",
    "    if return_decomposition:\n",
    "        return u,s,vh\n",
    "    else:\n",
    "        A_ = np.dot(u,np.dot(np.diag(s),vh))\n",
    "        return A_\n",
    "\n",
    "def plot_eigf(U0,y):\n",
    "    for i in range(y):\n",
    "        f = U0[:,i]\n",
    "        f = f.reshape(48,48)\n",
    "        plt.figure(figsize = (8,8))\n",
    "        plt.imshow(f,cmap = 'gray')\n",
    "        plt.show()\n",
    "        \n",
    "def clean(img, t1):\n",
    "    \n",
    "    img = img.reshape(48,48)\n",
    "    corr_skimage = match_template(img, t1, pad_input=True)\n",
    "    un = (corr_skimage > 0.53)\n",
    "    if (np.unique(un[12:22,9:18]) != False).any() and (np.unique(un[12:22,30:39]) != False).any() and (img.sum() > 220000) and (img.sum() < 400000):\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the data in the dataframes into the usable format\n",
    "\n",
    "full_data['pixels'] = full_data['pixels'].apply(lambda x: str2array(x))\n",
    "\n",
    "full_data['emotion'] = full_data['emotion'].apply(lambda x: np.int64(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING THE DATASET\n",
    "\n",
    "# needed inputs and templates\n",
    "\n",
    "img = full_data['pixels'].iloc[33].reshape(48,48)\n",
    "t1 = img[15:25,8:20]\n",
    "\n",
    "    \n",
    "# applying the cleaning function\n",
    "\n",
    "full_data['deсision'] = full_data['pixels'].apply(lambda x: clean(x, t1))\n",
    "\n",
    "\n",
    "# keep only the appropriate ones\n",
    "\n",
    "full_data=full_data.drop(full_data[full_data['deсision']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6259"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[5843 2698 2068 1673 2108 3530 1651 1123 4502 4852  889 5867  275 2624\\n 5752  160 4139 5787 4560 3773 3989 1243 4801 4207 1046 2993 2629 5905\\n 2099 1230 1593 5679 6245 3153 6166 1061 3617 5354 1189 5428 1555 4342\\n 4486 5188  855 3313  958 1828 6157 1338 4652 3073  302 3970 1175 1851\\n  791  681 4272 1172 6127  853  915 5881  307 1330 2358 5211 3796 5442\\n 2573  378 1444 4742 2591 3102  159 5217  985 5390 5732 5244  483 1399\\n 1648 2064 6250 1473 3461  801 2531 1587 2901 1184 1842 5581 5765 4723\\n  986 4680 1745 3910 5288 3705 3090 2397 3133 4334 4062 4041 5768 4010\\n 4257  329  460 3949 3131 1769 4532 4971 5855 5307 3657 1055  198 2274\\n 3353  463 5904  289 3482 4681 4858 2219 2041 2743 3015 2147 4843 1919\\n  804 4304   25  566 3254 1079 3724 5118  851  322 3456 5983 4208 2185\\n 4978  395 1434   54  282  637  929  883 4221 1813 5294 5518 3488 3510\\n 5528 4816  414 1968 1285 1406 4389 5343 2871  670 1010 2817 1715 5727\\n 2815 3428 4038 2546  334 2580  642 3312  452 2414 4515 2456  683 6181\\n 6116 2900 3772 1656 6170 4092 1951 2027 3497 4215 5818 5105 2966 3026\\n 4748  493 4561 6010 3491 3204 1950 1143 5945  927 2979 3789 5336 5082\\n 5216 1028 2327 4176 1190 3267  424 4183 1031 3195 1366  866 6237 2445\\n 4377 1579 4521 4156 1734 4091 2961  605 2790 4554 4704 1108 3971 3842\\n 5091 3978 5424 1863  363 5094 2898 3031 2314 4752 3819  966 6075 4889\\n  921  102 6131 3352 1127  733 5694 6055 3659 5831 3893  771 1476 1557\\n 3421 3113 3770 4624 5096 3288 5447 1803 2469  779 5425  760 6066 2013\\n 3092 4522 5932 5187 3450 4620 2917 4284  669 2882  813 5663 5339   85\\n 4392 1334  789 4465 2204 4726 2381  911  873 4007 1223 5958 4267 2711\\n 4127 2089 4836 1790 5076 2946 3735 3111 2484 1698 3059 3722 2261 4296\\n 3712 4641 4708 1211 2852 1644 2131 1103 1266 4223 5878 2032  754 2451\\n 2550 6249 6257  230 5340 5684 5323 1645 4175 3241 4539 6239  449 3950\\n 5548  728 4877 4902 5300 1513 4136 3913 1225 2356 1268 6037 4493  574\\n  299 2731 1532 4692 2078 1212 4757 1688 6100 5167 6241 1778  944 1634\\n 3725 1078 1929 1270 1069 4719 1450  323 4130 1350 3812 4327 5251 4361\\n 1065 1396 2757 2818 3929 1122  283 1597 3420 3707 5297 2583 4427 1283\\n 5594 4418 1537 2777 3320 3462  885 2220 5628 5981 1741 2634 2106 4227\\n  821 1383 2619 4754 1901 4929 4143 5357 1152 5585 5800 5882  552 3607\\n 1541 3696 4101 4616 2387 4633 5667 5469 4565 3394  903 2140 1603 2523\\n 5045 4387 3377 1365  980  324 1034 1237 3579 2155 5394 4064 2113 5986\\n 3618  274 1116 5232 4685  902 1844  266 5639 5475 2146 4589  318 2637\\n 5951 2012 1760  461  532 3957 1788 5108 6069 5258  220 1536 5833 1009\\n 5534 1880 1888 3322 1151 3367 1988 4294 6089 5988 1747 5398  895  691\\n 3987 5851 2306 1395  519 1975  706 2474   62 3830  847  937  510 6061\\n 3156 3872 4785 2379 2422 5551 1317 3821 2606 5712  585 1004 1319 3699\\n 3580 6201 5030 6228   17 2507 1647 3004 3856 4683  677 4664  846 2097\\n 1369 2486 2388 6210 4140 5571 4663 2599  256 1052 4124 4659 1565 2438\\n 5703  772 4882 5869 3194  869 6195 4171 1302 2468 1799 4352 2642 5257\\n 1502  182 4179 1808 2780 5625 1111 1382  560 3514 4084 2663 2029 4919\\n 1245 5117 5025 3489  345 4913 2398 1095  908 4810 4177 2442 3024 2323\\n 3146 4268 3679 1005  815 3747 2452 3061 4870 2603 4734 3645 4898 4571\\n 3143 5529 5050 5897 1876 2292 5919 5543 1058 1961  432  828 5269 3240\\n 6105 2578 1998 1011 2176 4693 5758 2980 5264 1967  105 3798 1313 2141\\n 1293 6227 1262 2373  817 5763 3873 2479 3799 5206  767 6233  129 6029\\n 1802 3904 2434 5860 6094  797 4448  249   48 4364 2143 4421 4731 5271\\n 2612 5226 4654 5034 5978 4042 4144 4305  499 2487 2722 4128  654 3606\\n 3513 3411 1048 3784 4485 2661 3458  438 2938 3523 4089 3120  258 4385\\n 4861  592 4079 2997 6134 2102 5178 3675 1469 6027 1357 2142 3325  453\\n 1305   80 3825 1915 2994 2162 2392 5600 4117 4490  659 5889 1117 1484\\n 1220 3652  983 4149   22 5431 5077 1681 1908 5184 1370 1486  795 4592\\n 5737 2427 4995 5713 5247 2262 6041 5448 1731 5225 1398  157 5924 2639\\n 1796 5946   84 1351 4432 1013 3154 4081 5507  200 5536  590 2239 2734\\n  914  459  399 1277 1348 2170  225 1325 2410 5453 5086 3014 4712 2792\\n 2236 1635 5544 1564 5331  698  440 5922  170  852 4451 1932 2334 5643\\n 2301 5176 5730 4319 4774  814  617  377 2668 3886 2198 3261 5682 4314\\n  620 2925 2276  621 1201 3182 3827 1852 2342 1198  355 1523 4330 2299\\n  116 3710 1996 3953 5617 1581  517  423 2755 4759 1633 1887 5261 2854\\n 3226 2313 1684 3894 3668 4078 5169 1342 4489 4732 4643  470 5290 2061\\n 5204 2094 1375  165 3053 1291 2503 3979 2182 2995 2371 3797 2201 3969\\n 4941 3647 4000 1295 6000 1264 2825 2737  784 4981  708 5541 2367 5749\\n 5646 1834 3751 5119 1926 3356 1783 3101 1432 4464 2330 4826 4358 5910\\n 2290  180 3385 5721 4899 2168 5651 1119 2083 1096 3538 3890 2369 1830\\n 3846  671  413 4166 1792 2923 5457 1244 1917 1548 2812  422 5014 4040\\n 3188 1855 3436 4351 5747 4996 3787 2648 2770 1324 4753 2753  580 4837\\n 1057 6021  137 5498 3794 4027 3996 3738 6013 3122 3588 4724 2749 5093\\n  259 2988 3237  391 6109 1609 5205 3678 3764   66 5151 5044 5303 5868\\n 4636 6135 3035  286 2350 1310 2621  576 2248 3945] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-68c3baa3e865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mfull_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4168\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4169\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4170\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4171\u001b[0m         )\n\u001b[0;32m   4172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5281\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5282\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[5843 2698 2068 1673 2108 3530 1651 1123 4502 4852  889 5867  275 2624\\n 5752  160 4139 5787 4560 3773 3989 1243 4801 4207 1046 2993 2629 5905\\n 2099 1230 1593 5679 6245 3153 6166 1061 3617 5354 1189 5428 1555 4342\\n 4486 5188  855 3313  958 1828 6157 1338 4652 3073  302 3970 1175 1851\\n  791  681 4272 1172 6127  853  915 5881  307 1330 2358 5211 3796 5442\\n 2573  378 1444 4742 2591 3102  159 5217  985 5390 5732 5244  483 1399\\n 1648 2064 6250 1473 3461  801 2531 1587 2901 1184 1842 5581 5765 4723\\n  986 4680 1745 3910 5288 3705 3090 2397 3133 4334 4062 4041 5768 4010\\n 4257  329  460 3949 3131 1769 4532 4971 5855 5307 3657 1055  198 2274\\n 3353  463 5904  289 3482 4681 4858 2219 2041 2743 3015 2147 4843 1919\\n  804 4304   25  566 3254 1079 3724 5118  851  322 3456 5983 4208 2185\\n 4978  395 1434   54  282  637  929  883 4221 1813 5294 5518 3488 3510\\n 5528 4816  414 1968 1285 1406 4389 5343 2871  670 1010 2817 1715 5727\\n 2815 3428 4038 2546  334 2580  642 3312  452 2414 4515 2456  683 6181\\n 6116 2900 3772 1656 6170 4092 1951 2027 3497 4215 5818 5105 2966 3026\\n 4748  493 4561 6010 3491 3204 1950 1143 5945  927 2979 3789 5336 5082\\n 5216 1028 2327 4176 1190 3267  424 4183 1031 3195 1366  866 6237 2445\\n 4377 1579 4521 4156 1734 4091 2961  605 2790 4554 4704 1108 3971 3842\\n 5091 3978 5424 1863  363 5094 2898 3031 2314 4752 3819  966 6075 4889\\n  921  102 6131 3352 1127  733 5694 6055 3659 5831 3893  771 1476 1557\\n 3421 3113 3770 4624 5096 3288 5447 1803 2469  779 5425  760 6066 2013\\n 3092 4522 5932 5187 3450 4620 2917 4284  669 2882  813 5663 5339   85\\n 4392 1334  789 4465 2204 4726 2381  911  873 4007 1223 5958 4267 2711\\n 4127 2089 4836 1790 5076 2946 3735 3111 2484 1698 3059 3722 2261 4296\\n 3712 4641 4708 1211 2852 1644 2131 1103 1266 4223 5878 2032  754 2451\\n 2550 6249 6257  230 5340 5684 5323 1645 4175 3241 4539 6239  449 3950\\n 5548  728 4877 4902 5300 1513 4136 3913 1225 2356 1268 6037 4493  574\\n  299 2731 1532 4692 2078 1212 4757 1688 6100 5167 6241 1778  944 1634\\n 3725 1078 1929 1270 1069 4719 1450  323 4130 1350 3812 4327 5251 4361\\n 1065 1396 2757 2818 3929 1122  283 1597 3420 3707 5297 2583 4427 1283\\n 5594 4418 1537 2777 3320 3462  885 2220 5628 5981 1741 2634 2106 4227\\n  821 1383 2619 4754 1901 4929 4143 5357 1152 5585 5800 5882  552 3607\\n 1541 3696 4101 4616 2387 4633 5667 5469 4565 3394  903 2140 1603 2523\\n 5045 4387 3377 1365  980  324 1034 1237 3579 2155 5394 4064 2113 5986\\n 3618  274 1116 5232 4685  902 1844  266 5639 5475 2146 4589  318 2637\\n 5951 2012 1760  461  532 3957 1788 5108 6069 5258  220 1536 5833 1009\\n 5534 1880 1888 3322 1151 3367 1988 4294 6089 5988 1747 5398  895  691\\n 3987 5851 2306 1395  519 1975  706 2474   62 3830  847  937  510 6061\\n 3156 3872 4785 2379 2422 5551 1317 3821 2606 5712  585 1004 1319 3699\\n 3580 6201 5030 6228   17 2507 1647 3004 3856 4683  677 4664  846 2097\\n 1369 2486 2388 6210 4140 5571 4663 2599  256 1052 4124 4659 1565 2438\\n 5703  772 4882 5869 3194  869 6195 4171 1302 2468 1799 4352 2642 5257\\n 1502  182 4179 1808 2780 5625 1111 1382  560 3514 4084 2663 2029 4919\\n 1245 5117 5025 3489  345 4913 2398 1095  908 4810 4177 2442 3024 2323\\n 3146 4268 3679 1005  815 3747 2452 3061 4870 2603 4734 3645 4898 4571\\n 3143 5529 5050 5897 1876 2292 5919 5543 1058 1961  432  828 5269 3240\\n 6105 2578 1998 1011 2176 4693 5758 2980 5264 1967  105 3798 1313 2141\\n 1293 6227 1262 2373  817 5763 3873 2479 3799 5206  767 6233  129 6029\\n 1802 3904 2434 5860 6094  797 4448  249   48 4364 2143 4421 4731 5271\\n 2612 5226 4654 5034 5978 4042 4144 4305  499 2487 2722 4128  654 3606\\n 3513 3411 1048 3784 4485 2661 3458  438 2938 3523 4089 3120  258 4385\\n 4861  592 4079 2997 6134 2102 5178 3675 1469 6027 1357 2142 3325  453\\n 1305   80 3825 1915 2994 2162 2392 5600 4117 4490  659 5889 1117 1484\\n 1220 3652  983 4149   22 5431 5077 1681 1908 5184 1370 1486  795 4592\\n 5737 2427 4995 5713 5247 2262 6041 5448 1731 5225 1398  157 5924 2639\\n 1796 5946   84 1351 4432 1013 3154 4081 5507  200 5536  590 2239 2734\\n  914  459  399 1277 1348 2170  225 1325 2410 5453 5086 3014 4712 2792\\n 2236 1635 5544 1564 5331  698  440 5922  170  852 4451 1932 2334 5643\\n 2301 5176 5730 4319 4774  814  617  377 2668 3886 2198 3261 5682 4314\\n  620 2925 2276  621 1201 3182 3827 1852 2342 1198  355 1523 4330 2299\\n  116 3710 1996 3953 5617 1581  517  423 2755 4759 1633 1887 5261 2854\\n 3226 2313 1684 3894 3668 4078 5169 1342 4489 4732 4643  470 5290 2061\\n 5204 2094 1375  165 3053 1291 2503 3979 2182 2995 2371 3797 2201 3969\\n 4941 3647 4000 1295 6000 1264 2825 2737  784 4981  708 5541 2367 5749\\n 5646 1834 3751 5119 1926 3356 1783 3101 1432 4464 2330 4826 4358 5910\\n 2290  180 3385 5721 4899 2168 5651 1119 2083 1096 3538 3890 2369 1830\\n 3846  671  413 4166 1792 2923 5457 1244 1917 1548 2812  422 5014 4040\\n 3188 1855 3436 4351 5747 4996 3787 2648 2770 1324 4753 2753  580 4837\\n 1057 6021  137 5498 3794 4027 3996 3738 6013 3122 3588 4724 2749 5093\\n  259 2988 3237  391 6109 1609 5205 3678 3764   66 5151 5044 5303 5868\\n 4636 6135 3035  286 2350 1310 2621  576 2248 3945] not found in axis'"
     ]
    }
   ],
   "source": [
    "# Random train-test split\n",
    "\n",
    "random.seed = 42\n",
    "\n",
    "test_percentage = 0.2\n",
    "\n",
    "test_indices = np.random.choice(range(0,len(full_data)),\n",
    "                                      size = int(test_percentage*len(full_data)),\n",
    "                                      replace = False,)\n",
    "\n",
    "test_set = full_data.iloc[test_indices]\n",
    "full_data.drop(test_indices,axis = 0,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set.shape)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_data['Usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_data['deсision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[24, 32, 36, 30, 32, 23, 19, 20, 30, 41, 21, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>[55, 55, 55, 55, 55, 54, 60, 68, 54, 85, 151, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>[85, 84, 90, 121, 101, 102, 133, 153, 153, 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>[255, 254, 255, 254, 254, 179, 122, 107, 95, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  [70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...\n",
       "3        4  [24, 32, 36, 30, 32, 23, 19, 20, 30, 41, 21, 2...\n",
       "5        2  [55, 55, 55, 55, 55, 54, 60, 68, 54, 85, 151, ...\n",
       "8        3  [85, 84, 90, 121, 101, 102, 133, 153, 153, 169...\n",
       "9        2  [255, 254, 255, 254, 254, 179, 122, 107, 95, 1..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking a glipse over how do the images look like\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img0 = full_data['pixels'].iloc[10].reshape(48,48)\n",
    "plt.imshow(img0, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The ovarall idea of the pipeline\n",
    "\n",
    "# We need to form some dataset with balanced classes, e.g. 100 random images from each category\n",
    "# Then we build and approximation matrix F_norm, which can be induced by subtracting the mean and SVD truncation of the residual\n",
    "# We project the test images on our singular vector space and therefore we find the closest from the prospect of the cosine similarity image to the test one\n",
    "# We predict the label of the test image to be the same, as the label og the closest train one\n",
    "\n",
    "# We stabilize the result by feeding e.g. 11 different subdatasets (one may call them batches) to our model and decide the total prediction by common majority vote\n",
    "\n",
    "\n",
    "### NB f1_score would be used as the measure of quality in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to work on the non-preprocessed, raw dataset for the moment\n",
    "\n",
    "# we create subdatasets to work with eigenfaces\n",
    "\n",
    "subdata_0 = create_subset_labeled_with(0,full_data)\n",
    "subdata_1 = create_subset_labeled_with(1,full_data)\n",
    "subdata_2 = create_subset_labeled_with(2,full_data)\n",
    "subdata_3 = create_subset_labeled_with(3,full_data)\n",
    "subdata_4 = create_subset_labeled_with(4,full_data)\n",
    "subdata_5 = create_subset_labeled_with(5,full_data)\n",
    "subdata_6 = create_subset_labeled_with(6,full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [subdata_0,\n",
    "                    subdata_1,\n",
    "                    subdata_2,\n",
    "                    subdata_3,\n",
    "                    subdata_4,\n",
    "                    subdata_5,\n",
    "                    subdata_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 624/624 [00:04<00:00, 126.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# preparing the test data for quality check in the end\n",
    "\n",
    "TEST_BATCH_SIZE = len(test_set)\n",
    "testing_batch = construct_a_batch([test_set],TEST_BATCH_SIZE)\n",
    "F_test = create_F_matrix_from_subdataset(testing_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_test_norm = subtract_column_mean(F_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#HERE STARTS THE RUNNING OF A voting across sevaral models\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3459.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3849.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3299.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3285.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3301.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3301.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3287.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3459.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2878.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3293.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2562.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3008.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3642.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3466.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3649.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3008.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 4069.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3640.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2882.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3738.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2882.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3458.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3459.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3640.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3007.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3315.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3147.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3458.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3458.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3139.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3850.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3464.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2470.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3466.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3145.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3637.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3148.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3465.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2767.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3842.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3458.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3007.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2562.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3647.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3647.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3466.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3513.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3141.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 4072.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3649.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3853.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2881.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 4070.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2882.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3007.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3008.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3008.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3010.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2162.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2882.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2882.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2877.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3288.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3007.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3073.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2942.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3146.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3288.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3007.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2652.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3843.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3299.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3007.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3641.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3458.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3459.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3975.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 4070.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3144.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3459.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2767.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3294.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 3737.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for iters in range(101):\n",
    "\n",
    "    # we construct a class - balanced subdataset\n",
    "\n",
    "    TRAIN_BATCH_SIZE = 10\n",
    "    batch = construct_a_batch(list_of_datasets,TRAIN_BATCH_SIZE)\n",
    "    # sizes must be (7*second_arg,2)\n",
    "\n",
    "    # we construct a matrix by columns (vectorized images of the test dataset)\n",
    "    F0 = create_F_matrix_from_subdataset(batch)\n",
    "\n",
    "    # we subtract the mean column to normalize it\n",
    "\n",
    "    F0_norm = subtract_column_mean(F0)\n",
    "\n",
    "    # we select the approximation strength (rank of truncation), which, obviously, should be less then min(F0.shape[0],F0.shape[1])\n",
    "\n",
    "    R = 10\n",
    "\n",
    "\n",
    "    # we build an R-rank approximation of the centralized F-matrix\n",
    "\n",
    "    F0_norm_approx = approximate_with_rank(F0_norm, r = R)\n",
    "\n",
    "    # we glimpse at the uniformness of approximation mistakes\n",
    "\n",
    "    #plt.spy(F0_norm - F0_norm_approx,10); \n",
    "\n",
    "    # we decompose it again, but now keeping the factors\n",
    "\n",
    "    U0,S0,Vh0 = approximate_with_rank(F0_norm, \n",
    "                                      r = R,\n",
    "                                      return_decomposition=True)\n",
    "\n",
    "    # we have a glimpse at the first columns of the U matrix, which form a basis in the space of faces (first several)\n",
    "    # we wont need it in the last pipeline\n",
    "    #plot_eigf(U0,3)\n",
    "\n",
    "    # to make a projection of the correspondingly dimensioned vector on the subspace of eigenvectors, we need,\n",
    "    # taking into account the properties of U matrix (unitary), to Compute U^t@vec = coefficients in the basis\n",
    "\n",
    "    # jyst a debugging cell to check whether the model works on the only image\n",
    "\n",
    "    test_img_vec = F_test_norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # now we need to project our test images on the subspace induced by singular vectors\n",
    "\n",
    "    # we construct a projection matrix (U is unitary)\n",
    "\n",
    "    # the shape would be R by len(vec(img)) = 2304\n",
    "\n",
    "    projection_matrix = U0.T\n",
    "\n",
    "\n",
    "\n",
    "    # performing the projection\n",
    "\n",
    "    f2 = projection_matrix@test_img_vec\n",
    "\n",
    "    # in general in is R by the TEST_BATCH_SIZE\n",
    "\n",
    "    \n",
    "\n",
    "    # the correspondency matrix, with which to compare (we search for the image with quite the same coefficients in linear combination)\n",
    "\n",
    "    W = np.diag(S0)@Vh0\n",
    "\n",
    "\n",
    "    dist = (cosine_similarity(f2.T, W.T).argmax(axis=1))\n",
    "\n",
    "\n",
    "\n",
    "    prediction = batch['emotion'].iloc[dist]\n",
    "    prediction = np.array(prediction)\n",
    "    #print(prediction[:5])\n",
    "    #print(prediction.shape)\n",
    "\n",
    "    y_true = np.array(testing_batch['emotion'])\n",
    "\n",
    "    f1_score(y_true,\n",
    "             prediction,\n",
    "             average='micro')\n",
    "    \n",
    "    PREDICTIONS.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.concatenate(PREDICTIONS[-101:])\n",
    "p = p.reshape(-1,test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 625)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = np.int64(np.median(p,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29822841056586824"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_pred,y_true,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maksim Komatovskiy\\anaconda_\\envs\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=[0, 1, 2, 3, 4, 5, 6] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  3,  1,  2,  0,  2,  1],\n",
       "       [29,  5, 24, 21, 15, 12, 24],\n",
       "       [53,  5, 61, 94, 52, 41, 70],\n",
       "       [ 9,  0,  7, 22, 16, 18, 29],\n",
       "       [ 0,  0,  1,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.confusion_matrix(all_pred,y_true,[0,1,2,3,4,5,6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
